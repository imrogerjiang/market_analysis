{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPczmoY/sKl72Sqg4U9KzLS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imrogerjiang/market_analysis/blob/main/Market_Analysis_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGFALs4x_D6v",
        "outputId": "f17ae66c-23a4-4727-f73a-e74244772e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from typing import Dict, Optional, List\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Listings"
      ],
      "metadata": {
        "id": "FfePqEj2LHmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Constants ----------\n",
        "YEAR_MIN, YEAR_MAX = 1980, 2035\n",
        "ORDER: List[str] = ['href', 'year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']\n",
        "\n",
        "YEAR_RE  = r'\\b(19[89]\\d|20[0-3]\\d)\\b'\n",
        "PRICE_RE = r'^\\s*\\$\\s*[\\d,]+(?:\\.\\d{2})?\\b'\n",
        "ODOM_RE  = r'^\\s*\\d{1,3}(?:,\\d{3})+\\s*km\\s*$'\n",
        "URL_RE   = r'^(?:https?://|www\\.)'\n",
        "TX, SELLER = {'automatic', 'manual'}, {'private', 'dealer used'}\n",
        "\n",
        "THRESH: Dict[str, float] = {\n",
        "    'year_make_model': 0.50,\n",
        "    \"listed_price\":           0.60,\n",
        "    'transmission':    0.80,\n",
        "    'odometer':        0.60,\n",
        "    'seller_type':     0.70,\n",
        "}\n",
        "\n",
        "# ---------- Predicates ----------\n",
        "def _ratio(mask: pd.Series) -> float:\n",
        "    return float(mask.mean()) if len(mask) else 0.0\n",
        "\n",
        "def _yr_ok(s: pd.Series) -> pd.Series:\n",
        "    years = pd.to_numeric(s.astype(str).str.extract(YEAR_RE, expand=False), errors='coerce')\n",
        "    return years.between(YEAR_MIN, YEAR_MAX)\n",
        "\n",
        "PRED = {\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    \"listed_price\":           lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'transmission':    lambda s: s.astype(str).str.strip().str.lower().isin(TX),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "    'seller_type':     lambda s: s.astype(str).str.strip().str.lower().isin(SELLER),\n",
        "}\n",
        "\n",
        "# ---------- Core ----------\n",
        "def identify_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identify and map each canonical column.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in ORDER}\n",
        "\n",
        "    href_col = cols[0]\n",
        "\n",
        "    # exclude URL-like columns from other detection\n",
        "    url_ratio = {c: _ratio(df[c].astype(str).str.contains(URL_RE, case=False, na=False)) for c in cols}\n",
        "    urlish = {c for c, r in url_ratio.items() if r >= 0.50}\n",
        "    blocked = {href_col} | urlish\n",
        "\n",
        "    remaining = [c for c in cols if c not in blocked]\n",
        "    picks = {t: None for t in PRED}\n",
        "\n",
        "    for t in PRED:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED[t](df[c])) for c in remaining}\n",
        "        best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "        if best_score >= THRESH[t]:\n",
        "            picks[t] = best_col\n",
        "            remaining.remove(best_col)\n",
        "\n",
        "    trim_col = None\n",
        "    ymm = picks.get('year_make_model')\n",
        "    if ymm in cols:\n",
        "        i = cols.index(ymm)\n",
        "        if i + 1 < len(cols):\n",
        "            trim_col = cols[i + 1]\n",
        "\n",
        "    return {'href': href_col, **picks, 'trim': trim_col}\n",
        "\n",
        "# ---------- Cleaning ----------\n",
        "def clean_and_rename_cs(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Detect, rename, clean numeric/text data, and return standardized columns.\"\"\"\n",
        "    mapping = identify_columns(df)\n",
        "    out = pd.DataFrame()\n",
        "\n",
        "    # Map columns\n",
        "    if mapping['href'] is not None:\n",
        "        out['href'] = df[mapping['href']]\n",
        "    for col in ['year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']:\n",
        "        src = mapping.get(col)\n",
        "        if src is not None:\n",
        "            out[col] = df[src]\n",
        "\n",
        "    # Split \"year make model\"\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_cols = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        split_cols.columns = ['year', 'make', 'model']\n",
        "        out = pd.concat([out, split_cols], axis=1)\n",
        "\n",
        "    # Clean hrefs (remove query strings)\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    # Clean numeric columns\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            out[col] = (\n",
        "                out[col].astype(str)\n",
        "                .replace('[^\\\\d]', '', regex=True)\n",
        "                .replace('', pd.NA)\n",
        "                .astype(float)\n",
        "                .astype('Int64')\n",
        "            )\n",
        "\n",
        "    # Convert odometer to thousands of km\n",
        "    if 'odometer' in out.columns:\n",
        "        out['odometer'] = out['odometer'] // 1000\n",
        "\n",
        "    # Add scrape date\n",
        "    out['date_scraped'] = datetime.today().date()\n",
        "\n",
        "    # Build final tidy table\n",
        "    final_cols = ['href', 'year', 'make', 'model', \"listed_price\", 'trim', 'odometer', 'seller_type', 'date_scraped']\n",
        "    return out[[c for c in final_cols if c in out.columns]]\n",
        "\n",
        "def clean_fb(df):\n",
        "    # Split the b column into 'year', 'make', 'model'\n",
        "    df[['year', 'make', 'model']] = df['b'].str.split(expand=True, n=2)\n",
        "\n",
        "\n",
        "\n",
        "    # Rename columns\n",
        "    rename_columns = {\n",
        "        \"x1i10hfl href\": \"href\",\n",
        "        \"a\": \"listed_price\",\n",
        "        \"c\": \"location\",\n",
        "        \"d\": \"odometer\",\n",
        "    }\n",
        "\n",
        "    # If marketplace scrape does not have column \"c\"\n",
        "    if \"c\" not in df.columns:\n",
        "      df[\"c\"] = \"NA\"\n",
        "\n",
        "    df.rename(columns=rename_columns, inplace=True)\n",
        "\n",
        "\n",
        "    # removing query string\n",
        "    df[\"href\"] = df['href'].str.split('?').str[0]\n",
        "\n",
        "    # Convert price and odometer columns to integers\n",
        "    df=df[df[\"listed_price\"]!=\"Free\"]\n",
        "    df[\"listed_price\"] = df[\"listed_price\"].replace(r'[^\\d]', '', regex=True).astype(float).astype('Int64')\n",
        "    df['odometer'] = df['odometer'].replace(r'[^\\d]', '', regex=True).astype(float).astype('Int64')\n",
        "\n",
        "    # Add a column with today's date\n",
        "    df['date_scraped'] = datetime.today().date()\n",
        "\n",
        "    # Removing listings with null values\n",
        "    df = df.dropna(subset=[\"listed_price\",\"odometer\",\"year\"])\n",
        "\n",
        "    # Remove crashed listings\n",
        "    df=df[df[\"listed_price\"]!=1234]\n",
        "    df=df[df[\"listed_price\"]!=12345]\n",
        "\n",
        "    # Select only the required columns in order\n",
        "    final_columns = ['href', 'year', 'make', 'model', \"listed_price\", 'odometer', 'location', 'date_scraped']\n",
        "    df = df[final_columns]\n",
        "    return df"
      ],
      "metadata": {
        "id": "dqDA--uoLGKd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wU08_CxZLaak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "JPp8uZoZFruj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = [\n",
        "    # Honda Civic (AU)\n",
        "    [\"honda\", \"civic\", 2006, 2011, 8],\n",
        "    [\"honda\", \"civic\", 2012, 2015, 9],\n",
        "    [\"honda\", \"civic\", 2016, 2021, 10],\n",
        "    [\"honda\", \"civic\", 2022, 2024, 11],\n",
        "\n",
        "    # Honda Jazz (AU)\n",
        "    [\"honda\", \"jazz\", 2008, 2013, 2],\n",
        "    [\"honda\", \"jazz\", 2014, 2020, 3],\n",
        "\n",
        "    # Hyundai i30 (AU)\n",
        "    [\"hyundai\", \"i30\", 2007, 2011, 1],\n",
        "    [\"hyundai\", \"i30\", 2012, 2016, 2],\n",
        "    [\"hyundai\", \"i30\", 2017, 2023, 3],\n",
        "\n",
        "    # Toyota Corolla (AU)\n",
        "    [\"toyota\", \"corolla\", 2007, 2012, 10],\n",
        "    [\"toyota\", \"corolla\", 2013, 2018, 11],\n",
        "    [\"toyota\", \"corolla\", 2019, 2024, 12],\n",
        "\n",
        "    # Toyota Yaris (AU)\n",
        "    [\"toyota\", \"yaris\", 2006, 2010, 2],\n",
        "    [\"toyota\", \"yaris\", 2011, 2019, 3],\n",
        "    [\"toyota\", \"yaris\", 2020, 2024, 4],\n",
        "\n",
        "    # Mazda 2 (AU)\n",
        "    [\"mazda\", \"2\", 2007, 2014, 2],\n",
        "    [\"mazda\", \"2\", 2015, 2024, 3],\n",
        "\n",
        "    # Mazda 3 (AU)\n",
        "    [\"mazda\", \"3\", 2009, 2013, 2],\n",
        "    [\"mazda\", \"3\", 2014, 2018, 3],\n",
        "    [\"mazda\", \"3\", 2019, 2024, 4],\n",
        "]\n",
        "\n",
        "gen_lookup = pd.DataFrame(temp, columns=[\"make\",\"model\",\"year_start\",\"year_end\",\"gen\"])\n",
        "gen_lookup.to_csv(f\"/content/drive/Shareddrives/market_analysis_v2/gen_lookup.csv\", index=False)"
      ],
      "metadata": {
        "id": "zM0tKYT5_MmS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listings = pd.DataFrame(columns=[\n",
        "    \"href\",\n",
        "    \"year\",\n",
        "    \"make\",\n",
        "    \"model\",\n",
        "    \"listed_price\",\n",
        "    \"nego_price\",\n",
        "    \"trim\",\n",
        "    \"odometer\",\n",
        "    \"seller_type\",\n",
        "    \"date_scrapped\",\n",
        "    \"location\",\n",
        "    \"marketplace\",\n",
        "    \"status\",\n",
        "])\n"
      ],
      "metadata": {
        "id": "JCbstxMBFxfk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path to your folder\n",
        "folder = \"/content/drive/Shareddrives/data/market_analysis/*.csv\"\n",
        "\n",
        "# collect all CSV file paths\n",
        "files = glob.glob(folder)\n",
        "\n",
        "# load all into one list\n",
        "dfs = []\n",
        "for f in files:\n",
        "    df = pd.read_csv(f)\n",
        "    df=df.rename(columns={\"date_scraped\":\"date_found\"})\n",
        "    dfs.append(df)\n",
        "\n",
        "# combine everything\n",
        "combined = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# ensure date_found is datetime\n",
        "combined[\"date_found\"] = pd.to_datetime(combined[\"date_found\"], errors=\"coerce\")\n",
        "\n",
        "# sort by date_found so the latest is kept\n",
        "combined = combined.sort_values(\"date_found\")\n",
        "\n",
        "# drop duplicates by href, keeping latest\n",
        "combined = combined.drop_duplicates(subset=\"href\", keep=\"last\")\n",
        "\n",
        "# if you want it back into your 'listings' variable\n",
        "listings = combined.reset_index(drop=True)\n",
        "\n",
        "# Consolidate 'price' into 'listed_price' where 'listed_price' is null\n",
        "# This handles cases where some CSVs use 'price' and others 'listed_price'\n",
        "if 'price' in listings.columns and 'listed_price' in listings.columns:\n",
        "    listings['listed_price'] = listings['listed_price'].fillna(listings['price'])\n",
        "    listings = listings.drop(columns=['price'])\n",
        "elif 'price' in listings.columns and 'listed_price' not in listings.columns:\n",
        "    listings = listings.rename(columns={'price': 'listed_price'})\n",
        "\n",
        "# Apply the desired data types after loading and combining the data\n",
        "listings = listings.astype({\n",
        "    \"href\": \"string\",\n",
        "    \"year\": \"Int64\",\n",
        "    \"make\": \"string\",\n",
        "    \"model\": \"string\",\n",
        "    \"listed_price\": \"Int64\",\n",
        "    \"trim\": \"string\",\n",
        "    \"odometer\": \"Int64\",\n",
        "    \"seller_type\": \"string\",\n",
        "    \"location\": \"string\"\n",
        "})"
      ],
      "metadata": {
        "id": "CE7LShjSGY3v"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listings.to_csv(f\"/content/drive/Shareddrives/market_analysis_v2/listings.csv\", index=False)"
      ],
      "metadata": {
        "id": "mTu5HXCxOGqu"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}