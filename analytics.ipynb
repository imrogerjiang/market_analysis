{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "36d9e666",
      "metadata": {
        "id": "36d9e666"
      },
      "source": [
        "## Market Analysis (Initial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec0cff1",
      "metadata": {
        "id": "8ec0cff1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79dc2e27",
      "metadata": {
        "id": "79dc2e27"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘    âœï¸ VA TO EDIT            â•‘\n",
        "\n",
        "client_id = \"jahin_20251026\"\n",
        "budget = [12_000, 18_000]\n",
        "year = 2012                     # Newer than or equal to\n",
        "odo = [50, 200]                 # Odometer between\n",
        "model_short = \"camry\"\n",
        "model_name = \"Toyota Camry\"\n",
        "\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1fb75d",
      "metadata": {
        "id": "be1fb75d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "# ---------- Constants ----------\n",
        "YEAR_MIN, YEAR_MAX = 1980, 2035\n",
        "ORDER: List[str] = ['href', 'year_make_model', 'trim', 'price', 'transmission', 'odometer', 'seller_type']\n",
        "\n",
        "YEAR_RE  = r'\\b(19[89]\\d|20[0-3]\\d)\\b'\n",
        "PRICE_RE = r'^\\s*\\$\\s*[\\d,]+(?:\\.\\d{2})?\\b'\n",
        "ODOM_RE  = r'^\\s*\\d{1,3}(?:,\\d{3})+\\s*km\\s*$'\n",
        "URL_RE   = r'^(?:https?://|www\\.)'\n",
        "TX, SELLER = {'automatic', 'manual'}, {'private', 'dealer used'}\n",
        "\n",
        "THRESH: Dict[str, float] = {\n",
        "    'year_make_model': 0.50,\n",
        "    'price':           0.60,\n",
        "    'transmission':    0.80,\n",
        "    'odometer':        0.60,\n",
        "    'seller_type':     0.70,\n",
        "}\n",
        "\n",
        "# ---------- Predicates ----------\n",
        "def _ratio(mask: pd.Series) -> float:\n",
        "    return float(mask.mean()) if len(mask) else 0.0\n",
        "\n",
        "def _yr_ok(s: pd.Series) -> pd.Series:\n",
        "    years = pd.to_numeric(s.astype(str).str.extract(YEAR_RE, expand=False), errors='coerce')\n",
        "    return years.between(YEAR_MIN, YEAR_MAX)\n",
        "\n",
        "PRED = {\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    'price':           lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'transmission':    lambda s: s.astype(str).str.strip().str.lower().isin(TX),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "    'seller_type':     lambda s: s.astype(str).str.strip().str.lower().isin(SELLER),\n",
        "}\n",
        "\n",
        "# ---------- Core ----------\n",
        "def identify_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identify and map each canonical column.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in ORDER}\n",
        "\n",
        "    href_col = cols[0]\n",
        "\n",
        "    # exclude URL-like columns from other detection\n",
        "    url_ratio = {c: _ratio(df[c].astype(str).str.contains(URL_RE, case=False, na=False)) for c in cols}\n",
        "    urlish = {c for c, r in url_ratio.items() if r >= 0.50}\n",
        "    blocked = {href_col} | urlish\n",
        "\n",
        "    remaining = [c for c in cols if c not in blocked]\n",
        "    picks = {t: None for t in PRED}\n",
        "\n",
        "    for t in PRED:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED[t](df[c])) for c in remaining}\n",
        "        best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "        if best_score >= THRESH[t]:\n",
        "            picks[t] = best_col\n",
        "            remaining.remove(best_col)\n",
        "\n",
        "    trim_col = None\n",
        "    ymm = picks.get('year_make_model')\n",
        "    if ymm in cols:\n",
        "        i = cols.index(ymm)\n",
        "        if i + 1 < len(cols):\n",
        "            trim_col = cols[i + 1]\n",
        "\n",
        "    return {'href': href_col, **picks, 'trim': trim_col}\n",
        "\n",
        "# ---------- Cleaning ----------\n",
        "def clean_and_rename_cs(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Detect, rename, clean numeric/text data, and return standardized columns.\"\"\"\n",
        "    mapping = identify_columns(df)\n",
        "    out = pd.DataFrame()\n",
        "\n",
        "    # Map columns\n",
        "    if mapping['href'] is not None:\n",
        "        out['href'] = df[mapping['href']]\n",
        "    for col in ['year_make_model', 'trim', 'price', 'transmission', 'odometer', 'seller_type']:\n",
        "        src = mapping.get(col)\n",
        "        if src is not None:\n",
        "            out[col] = df[src]\n",
        "\n",
        "    # Split \"year make model\"\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_cols = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        split_cols.columns = ['year', 'make', 'model']\n",
        "        out = pd.concat([out, split_cols], axis=1)\n",
        "\n",
        "    # Clean hrefs (remove query strings)\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    # Clean numeric columns\n",
        "    for col in ['price', 'odometer']:\n",
        "        if col in out.columns:\n",
        "            out[col] = (\n",
        "                out[col].astype(str)\n",
        "                .replace('[^\\\\d]', '', regex=True)\n",
        "                .replace('', pd.NA)\n",
        "                .astype(float)\n",
        "                .astype('Int64')\n",
        "            )\n",
        "\n",
        "    # Convert odometer to thousands of km\n",
        "    if 'odometer' in out.columns:\n",
        "        out['odometer'] = out['odometer'] // 1000\n",
        "\n",
        "    # Add scrape date\n",
        "    out['date_scraped'] = datetime.today().date()\n",
        "\n",
        "    # Build final tidy table\n",
        "    final_cols = ['href', 'year', 'make', 'model', 'price', 'trim', 'odometer', 'seller_type', 'date_scraped']\n",
        "    return out[[c for c in final_cols if c in out.columns]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "442a7c00",
      "metadata": {
        "id": "442a7c00"
      },
      "outputs": [],
      "source": [
        "# Reading all carsales csvs\n",
        "# path = os.path.join(os.getcwd(), client_id)\n",
        "path = \"\"\n",
        "files = glob.glob(os.path.join(path, \"carsales*.csv\"))\n",
        "cs = pd.concat([clean_and_rename_cs(pd.read_csv(f)) for f in files], ignore_index=True)\n",
        "\n",
        "# Dropping duplicates\n",
        "cs['href'] = cs['href'].astype(str)\n",
        "before = len(cs)\n",
        "cs = cs.drop_duplicates(subset=['href'], keep='first')\n",
        "print(f\"Dropped {before - len(cs)} duplicate rows.\")\n",
        "\n",
        "\n",
        "cs.head(5)\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘    ğŸ” VA TO CHECK OUTPUT    â•‘\n",
        "\n",
        "# 1. Text Roger if duplicate rows > 10\n",
        "# 2. Sense check each column\n",
        "\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f348ffd",
      "metadata": {
        "id": "8f348ffd"
      },
      "outputs": [],
      "source": [
        "def clean_fb(df):\n",
        "    # Split the b column into 'year', 'make', 'model'\n",
        "    df[['year', 'make', 'model']] = df['b'].str.split(expand=True, n=2)\n",
        "\n",
        "\n",
        "\n",
        "    # Rename columns\n",
        "    rename_columns = {\n",
        "        \"x1i10hfl href\": \"href\",\n",
        "        \"a\": \"price\",\n",
        "        \"c\": \"location\",\n",
        "        \"d\": \"odometer\",\n",
        "    }\n",
        "\n",
        "    # If marketplace scrape does not have column \"c\"\n",
        "    if \"c\" not in df.columns:\n",
        "      df[\"c\"] = \"NA\"\n",
        "\n",
        "    df.rename(columns=rename_columns, inplace=True)\n",
        "\n",
        "\n",
        "    # removing query string\n",
        "    df[\"href\"] = df['href'].str.split('?').str[0]\n",
        "\n",
        "    # Convert price and odometer columns to integers\n",
        "    df=df[df['price']!=\"Free\"]\n",
        "    df['price'] = df['price'].replace(r'[^\\d]', '', regex=True).astype(float).astype('Int64')\n",
        "    df['odometer'] = df['odometer'].replace(r'[^\\d]', '', regex=True).astype(float).astype('Int64')\n",
        "\n",
        "    # Add a column with today's date\n",
        "    df['date_scraped'] = datetime.today().date()\n",
        "\n",
        "    # Removing listings with null values\n",
        "    df = df.dropna(subset=[\"price\",\"odometer\",\"year\"])\n",
        "\n",
        "    # Select only the required columns in order\n",
        "    final_columns = ['href', 'year', 'make', 'model', 'price', 'odometer', 'location', 'date_scraped']\n",
        "    df = df[final_columns]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b27d2c38",
      "metadata": {
        "id": "b27d2c38"
      },
      "outputs": [],
      "source": [
        "files = glob.glob(os.path.join(path, \"facebook*.csv\"))\n",
        "fb = pd.concat([clean_fb(pd.read_csv(f)) for f in files], ignore_index=True)\n",
        "\n",
        "fb['href'] = fb['href'].astype(str)\n",
        "before = len(fb)\n",
        "print(f\"Rows starting {len(fb)}.\")\n",
        "fb = fb.drop_duplicates(subset=['href'], keep='first')\n",
        "print(f\"Rows remaining {len(fb)}.\")\n",
        "\n",
        "fb.head(5)\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘    ğŸ” VA TO CHECK OUTPUT    â•‘\n",
        "\n",
        "# 1. Check that number of rows remaining is approximately files*40\n",
        "# 2. Sense check each column\n",
        "\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79472850",
      "metadata": {
        "id": "79472850"
      },
      "outputs": [],
      "source": [
        "df = cs\n",
        "df = pd.concat([cs, fb], ignore_index=True)\n",
        "\n",
        "# Remove duplicates for cars in both carsales/fb marketplace\n",
        "print(f\"Rows starting {len(df)}.\")\n",
        "df=df.drop_duplicates(subset=['year', 'price', 'odometer'])\n",
        "print(f\"Rows remaining {len(df)}.\")\n",
        "\n",
        "# Save file\n",
        "# df.to_csv(f\"{path}/{model_short}_all.csv\", index=False)\n",
        "df.to_csv(f\"{client_id}_all.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(f\"{client_id}_all.csv\")"
      ],
      "metadata": {
        "id": "5Qf_ADJUUzlh"
      },
      "id": "5Qf_ADJUUzlh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1aa1271",
      "metadata": {
        "id": "a1aa1271"
      },
      "outputs": [],
      "source": [
        "plt.scatter(df['odometer'], df['price'], label='Data', color='lightsteelblue', s=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4932b1ad",
      "metadata": {
        "id": "4932b1ad"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘    âœï¸ VA TO EDIT            â•‘\n",
        "\n",
        "# Removing listings with unrealistic low price\n",
        "# Code keeps cars with price>X\n",
        "df1 = df[df[\"price\"]>5000]\n",
        "\n",
        "# Remove listings with high odometer\n",
        "# Code keeps cars with odo<X\n",
        "df1 = df1[df1[\"odometer\"]<350]\n",
        "\n",
        "# Remove listings with unrealistic low odometer\n",
        "# Code keeps cars with odo>X\n",
        "df1 = df1[df1[\"odometer\"]>50]\n",
        "\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "plt.scatter(df1['odometer'], df1['price'], label='Data', color='lightsteelblue', s=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d440aed1",
      "metadata": {
        "scrolled": true,
        "id": "d440aed1"
      },
      "outputs": [],
      "source": [
        "# 0) Work on a real copy (kills SettingWithCopyWarning)\n",
        "df1 = df1.copy()\n",
        "\n",
        "# Truncate at 250,000km\n",
        "df1 = df1[df1[\"odometer\"]<250]\n",
        "\n",
        "# 1) Coerce to numeric (allow bad cells to become NaN)\n",
        "df1['year']     = pd.to_numeric(df1['year'], errors='coerce')\n",
        "df1['odometer'] = pd.to_numeric(df1['odometer'], errors='coerce')\n",
        "df1['price']    = pd.to_numeric(df1['price'], errors='coerce')\n",
        "\n",
        "# 2) Build X, y as float and drop rows with NaNs\n",
        "X_num = df1[['year','odometer']].astype(float)\n",
        "y_num = df1['price'].astype(float)\n",
        "keep  = X_num.notna().all(axis=1) & y_num.notna()\n",
        "\n",
        "X = sm.add_constant(X_num.loc[keep])\n",
        "y = y_num.loc[keep]\n",
        "\n",
        "# Optional sanity checks\n",
        "assert np.isfinite(X.to_numpy()).all() and np.isfinite(y.to_numpy()).all()\n",
        "assert X[['year','odometer']].std().gt(0).all()\n",
        "\n",
        "# 3) Fit and predict\n",
        "model = sm.OLS(y, X).fit()\n",
        "print(model.summary())\n",
        "\n",
        "df1.loc[keep, 'predicted_price'] = model.predict(X)\n",
        "df1.loc[keep, 'value_diff'] = df1.loc[keep, 'predicted_price'] - df1.loc[keep, 'price']\n",
        "\n",
        "print(f\"Used {keep.sum()} rows; dropped {len(df1) - keep.sum()} rows.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ea7bc9",
      "metadata": {
        "id": "02ea7bc9"
      },
      "outputs": [],
      "source": [
        "# Identify n best value cars\n",
        "within_crit = df1[\n",
        "    (df1[\"price\"]<budget[1]) & (df1['price']>budget[0])\n",
        "    & (df1['year']>=year)\n",
        "    & (df1['odometer']<odo[1]) & (df1['odometer']>odo[0])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "within_crit = df1[df1[\"href\"].isin([\n",
        "    \"https://www.carsales.com.au/cars/details/2017-toyota-camry-altise-auto/OAG-AD-25162216/\",\n",
        "    \"https://www.facebook.com/marketplace/item/1366403871677358/\",\n",
        "])]"
      ],
      "metadata": {
        "id": "sE6Z8QiG_Gb3"
      },
      "id": "sE6Z8QiG_Gb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46679745",
      "metadata": {
        "id": "46679745"
      },
      "outputs": [],
      "source": [
        "# Rank the top-n best-value cars (1 = best)\n",
        "best_n = within_crit.sort_values('value_diff', ascending=False).head(10).copy()\n",
        "best_n['rank'] = np.arange(1, len(best_n) + 1)\n",
        "\n",
        "other_listings = df1.merge(best_n, how=\"outer\", indicator=True) \\\n",
        "          .query('_merge == \"left_only\"') \\\n",
        "          .drop(columns=\"_merge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1053b3",
      "metadata": {
        "id": "8c1053b3"
      },
      "outputs": [],
      "source": [
        "for _, row in best_n.iterrows():\n",
        "    print(f\"Car {row['rank']}\")\n",
        "    print(f\"Link: {row['href']}\")\n",
        "    print(f\"Price: ${row['price']:,}\")\n",
        "    print(f\"Market Value: ${row['predicted_price']:,.0f}\")\n",
        "    print(f\"Year: {row['year']}\")\n",
        "    print(f\"Odometer: {row['odometer']:,.0f},000km\\n\")\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘     VA TO SAVE ğŸ’¾           â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Paste in Google Docs\n",
        "# clients/client_name [tab: Market Analysis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdd9c54",
      "metadata": {
        "scrolled": false,
        "id": "7cdd9c54"
      },
      "outputs": [],
      "source": [
        "# Function to format price axis\n",
        "def price_format(x, _):\n",
        "    return f'${int(x):,}'\n",
        "\n",
        "# Plotting\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Scatter (Year vs Price)\n",
        "ax1.scatter(other_listings['year'], other_listings['price'], label='Data', color='lightsteelblue', s=20)\n",
        "\n",
        "for _, row in best_n.iterrows():\n",
        "    ax1.scatter(row['year'], row['price'], s=70, facecolors='none',  linewidths=1.2)\n",
        "    ax1.text(row['year'], row['price'], str(int(row['rank'])),\n",
        "             ha='center', va='center', fontsize=10, fontweight='bold', color='red', alpha = 0.7\n",
        "#              bbox=dict(boxstyle='round,pad=0', fc='white', ec='none')\n",
        "            )\n",
        "\n",
        "# Regression line (fix odometer at mean)\n",
        "year_range = np.linspace(other_listings['year'].min(), other_listings['year'].max(), 100)\n",
        "mean_odometer = other_listings['odometer'].mean()\n",
        "X_line = pd.DataFrame({\n",
        "    'const': 1,\n",
        "    'year': year_range,\n",
        "    'odometer': [mean_odometer]*100\n",
        "})\n",
        "y_line = model.predict(X_line)\n",
        "ax1.plot(year_range, y_line, label='Regression line')\n",
        "\n",
        "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "ax1.yaxis.set_major_formatter(FuncFormatter(price_format))\n",
        "ax1.set_xlabel('Model Year')\n",
        "ax1.set_ylabel('Price')\n",
        "ax1.set_title(f\"{model_name} Price For Different Years\")\n",
        "\n",
        "# Scatter (Odometer vs Price)\n",
        "ax2.scatter(other_listings['odometer'], other_listings['price'], label='Data', color='lightsteelblue', s=20)\n",
        "\n",
        "for _, row in best_n.iterrows():\n",
        "    ax2.scatter(row['odometer'], row['price'], s=70, facecolors='none',  linewidths=1.2)\n",
        "    ax2.text(row['odometer'], row['price'], str(int(row['rank'])),\n",
        "             ha='center', va='center', fontsize=10, fontweight='bold', color='red', alpha = 0.7\n",
        "#              bbox=dict(boxstyle='round,pad=0', fc='white', ec='none')\n",
        "            )\n",
        "\n",
        "# Regression line (fix year at mean)\n",
        "odometer_range = np.linspace(other_listings['odometer'].min(), other_listings['odometer'].max(), 100)\n",
        "mean_year = other_listings['year'].mean()\n",
        "X_line2 = pd.DataFrame({\n",
        "    'const': 1,\n",
        "    'year': [mean_year]*100,\n",
        "    'odometer': odometer_range\n",
        "})\n",
        "y_line2 = model.predict(X_line2)\n",
        "ax2.plot(odometer_range, y_line2, label='Regression line')\n",
        "\n",
        "ax2.yaxis.set_major_formatter(FuncFormatter(price_format))\n",
        "ax2.set_xlabel('Odometer (thousand kms)')\n",
        "ax2.set_ylabel('Price')\n",
        "ax2.set_title(f\"{model_name} Price For Different Mileage\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘     VA TO SAVE ğŸ’¾           â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Paste in Google Docs\n",
        "# clients/client_name [tab: Market Analysis]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}